---
layout: post
categories: HADOOP
tags: 生态圈服务启动
---

# HADOOP生态圈服务启动

## 1.zookeeper 启动

```shell
#启动zookeper服务(搭建集群时一般所有虚拟机均要执行)
/export/servers/zookeeper-3.4.9/bin/zkServer.sh start
#查看zookeeper当前状态
/export/servers/zookeeper-3.4.9/bin/zkServer.sh status
```

## 2.mysql 启动

```shell
#启动mysql服务(mysql为hadoop生态圈的基础,必须要启动)
/etc/init.d/mysqld start
```

## 3.HADOOP 启动

```shell
#启动hadoop集群(大数据的核心,必须要启动)
cd /export/servers/hadoop-2.7.5/
#相当于启动 start-hfs.sh 和 start-yarn.sh
sbin/start-all.sh
#启动查看历史任务服务
sbin/mr-jobhistory-daemon.sh start historyserver
```

```http
#查看hdfs
http://node01:50070/explorer.html#/
#查看yarn集群
http://node01:8088/cluster
#查看历史完成的任务
http://node01:19888/jobhistory
```

## 4.HIVE 启动

```shell
#hive在hadoop中有着举足轻重的地位,以下两个服务切记要开(本人已经吃了很大的亏)
#此处hive应已经配置过环境变量

#启动后可以连接到 MYSQLserver(mysql连接不上一般为此处未启动,或配置文件hive-site.xml有问题)
#客户端连接metastore服务，metastore再去连接MySQL数据库来存取元数据。有了metastore服务，就可以有多个客户端同时连接，而且这些客户端不需要知道MySQL数据库的用户名和密码，只需要连接metastore 服务即可
hive --service metastore  &
#启动后可连接到hive-metastore(此处以经常出现问题)用来对数据库进行操作
hive -- service hiveserver2 &

```

## 5.FLUME 启动

```shell
#按自己的需求更改地址和conf文件名即可,此处均使用绝对路径(本命令实际为一行,本地执行时可换为相对路径)
/export/servers/apache-flume-1.8.0-bin/bin/flume-ng agent -c conf -f /export/servers/apache-flume-1.8.0-bin/conf/netcat-logger.conf -n a1 -Dflume.root.logger=INFO,console
```

## 6.AZKABAN 启动

```shell
#集群模式启动(需先进到azkaban安装录下,我的在node02下)
#启动exec(进入到exec-server目录下)
bin/start-exec.sh 
#需手动激活 executor 进入到c-server安装目录下,节点名字按需更改
curl -G "node02$(<./executor.port)/executor?action=activate" && echo
#启动web(进入到web-server目录下)
 bin/start-web.sh
#web查看AZKABAN
https://node02:8443
```

## 7.IMPAlA启动

```shell
#主节点node03启动以下三个服务进程
service impala-state-store start
service impala-catalog start
service impala-server start
#从节点启动node01与node02启动impala-server
service  impala-server  start
#查看impala进程是否存在
ps -ef | grep impala
#访问impalad的管理界面
http://node03:25000/
#访问statestored的管理界面
http://node03:25010/
#主节点任意目录均可启动impala(我的主节点为node03)
impala-shell
```

## 8.OOZIE启动

```shell
#oozie启动需要先开启history-server(前提hadoop已经启动)
#进入到hadoop主节点(我的在node01)
cd /export/servers/hadoop-2.7.5/
#启动 history-server(停止需把start改为stop即可)
mr-jobhistory-daemon.sh start historyserver
#通过浏览器访问 hadoop jobhistory 的 webui
http://node01:19888
#进入到oozie安装目录下
cd /export/servers/oozie-4.1.0-cdh5.14.0
#启动oozie服务(关闭只需把start改为stop即可)
bin/oozied.sh start
#浏览器页面访问 oozie
http://node03:11000/oozie/
```

## 9.HUE启动

```shell
#hue是任务调度工具,能够正确使用的前提是其他所有的框架都已正确安装
#先进入hue的安装目录(我的在node03)
cd /export/servers/hue-3.9.0-cdh5.14.0/
#启动hue
build/env/bin/supervisor
#页面访问路径
http://node03:8888

```

## 10.KAFKA启动

```shell
#进入kafka的安装目录(kafka为集群,依赖于zookeeper)
cd /export/servers/kafka_2.11-0.10.0.0
#前台启动
bin/kafka-server-start.sh config/server.properties
#后台启动
nohup bin/kafka-server-start.sh config/server.properties 2>&1 &
#停止服务
bin/kafka-server-stop.sh
#查看kafka进程有以下两个就OK了
2276 QuorumPeerMain
2687 Jps#输入jps
3056 Kafka
```



------



[^author]:zcc815, 未经本人允许,仅可随意查看!!!

