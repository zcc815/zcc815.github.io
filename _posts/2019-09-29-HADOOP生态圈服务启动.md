---
layout: post
categories: HADOOP
tags: 生态圈服务启动
---

# HADOOP生态圈服务启动

## 1.zookeeper 启动

```shell
#启动zookeper服务(搭建集群时一般所有虚拟机均要执行)
/export/servers/zookeeper-3.4.9/bin/zkServer.sh start
#查看zookeeper当前状态
/export/servers/zookeeper-3.4.9/bin/zkServer.sh status
```

## 2.mysql 启动

```shell
#启动mysql服务(mysql为hadoop生态圈的基础,必须要启动)
/etc/init.d/mysqld start
```

## 3.HADOOP 启动

```shell
#启动hadoop集群(大数据的核心,必须要启动)
cd /export/servers/hadoop-2.7.5/
#相当于启动 start-hfs.sh 和 start-yarn.sh
sbin/start-all.sh
#启动查看历史任务服务
sbin/mr-jobhistory-daemon.sh start historyserver
```

```http
#查看hdfs
http://node01:50070/explorer.html#/
#查看yarn集群
http://node01:8088/cluster
#查看历史完成的任务
http://node01:19888/jobhistory
```

## 4.HIVE 启动

```shell
#hive在hadoop中有着举足轻重的地位,以下两个服务切记要开(本人已经吃了很大的亏)
#此处hive应已经配置过环境变量

#启动后可以连接到 MYSQLserver(mysql连接不上一般为此处未启动,或配置文件hive-site.xml有问题)
#客户端连接metastore服务，metastore再去连接MySQL数据库来存取元数据。有了metastore服务，就可以有多个客户端同时连接，而且这些客户端不需要知道MySQL数据库的用户名和密码，只需要连接metastore 服务即可
hive --service metastore  &
#启动后可连接到hive-metastore(此处以经常出现问题)用来对数据库进行操作
hive -- service hiveserver2 &

```

## 5.FLUME 启动

```shell
#按自己的需求更改地址和conf文件名即可,此处均使用绝对路径(本命令实际为一行,本地执行时可换为相对路径)
/export/servers/apache-flume-1.8.0-bin/bin/flume-ng agent -c conf -f /export/servers/apache-flume-1.8.0-bin/conf/netcat-logger.conf -n a1 -Dflume.root.logger=INFO,console
```

## 6.AZKABAN 启动

```shell
#集群模式启动(需先进到azkaban安装录下)
#启动exec(进入到exec-server目录下)
bin/start-exec.sh 
#需手动激活 executor 进入到c-server安装目录下,节点名字按需更改
curl -G "node02$(<./executor.port)/executor?action=activate" && echo
#启动web(进入到web-server目录下)
 bin/start-web.sh
```

## 7.IMPAlA启动

```shell
#主节点node03启动以下三个服务进程
service impala-state-store start
service impala-catalog start
service impala-server start
#从节点启动node01与node02启动impala-server
service  impala-server  start
#查看impala进程是否存在
ps -ef | grep impala
#访问impalad的管理界面
http://node03:25000/
#访问statestored的管理界面
http://node03:25010/
```

[^author]:zcc815, 未经本人允许,仅可随意查看!!!

